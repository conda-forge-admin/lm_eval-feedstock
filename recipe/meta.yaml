{% set name = "lm_eval" %}
{% set version = "0.3.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/lm_eval-{{ version }}.tar.gz
  sha256: 643b12bf9374f4d7c78ce55471b6ad82c130ab1aa0577d97fdfa48875dbc598b

build:
  skip: true  # [py2k]
  skip: true  # [win]
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  build:
    - {{ compiler('cxx') }}
  host:
    - python
    - pip
  run:
    - python
    - datasets >=2.0.0
    - jsonlines
    - numexpr
    - openai >=0.6.4
    - pybind11 >=2.6.2
    - pycountry
    - pytablewriter
    - rouge-score >=0.0.4
    - sacrebleu ==1.5.0
    - scikit-learn >=0.24.1
    - sqlitedict
    - pytorch >=1.7
    - tqdm-multiprocess
    - transformers >=4.1
    - zstandard

test:
  imports:
    - lm_eval
    - scripts
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://github.com/EleutherAI/lm-evaluation-harness
  summary: A framework for evaluating autoregressive language models
  license: MIT
  license_file: LICENSE.md

extra:
  recipe-maintainers:
    - mediocretech
